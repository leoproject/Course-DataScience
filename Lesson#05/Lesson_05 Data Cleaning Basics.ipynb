{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UsjAN9diXQC7"
   },
   "source": [
    "## 1 Reading CSV Files with Encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7h7-ejxlX_st"
   },
   "source": [
    "So far, we've learned how to select, assign, and analyze data with pandas using pre-cleaned data. In reality, data is rarely in the format you need it to be to perform analysis. Data scientists commonly [spend over half their time cleaning data](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#20705a446f63), so knowing how to clean 'messy' data is an extremely important skill.\n",
    "\n",
    "In this lesson, you'll learn how to :\n",
    "\n",
    "- Clean columns names.\n",
    "- Extract and convert numeric values from string values.\n",
    "- Extract string data.\n",
    "- Work with missing values.\n",
    "\n",
    "We'll be working with **laptops.csv**, a CSV file containing information on about 1,300 laptop computers. The first five rows of the CSV file is shown below:\n",
    "\n",
    "| _ | Manufacturer | Model Name  | Category  | Screen Size | Screen                             | CPU                        | RAM  | Storage             | GPU                          | Operating System | Operating System Version | Weight | Price (Euros) |\n",
    "|---|--------------|-------------|-----------|-------------|------------------------------------|----------------------------|------|---------------------|------------------------------|------------------|--------------------------|--------|---------------|\n",
    "| 0 | Apple        | MacBook Pro | Ultrabook | 13.3\"       | IPS Panel Retina Display 2560x1600 | Intel Core i5 2.3GHz       | 8GB  | 128GB SSD           | Intel Iris Plus Graphics 640 | macOS            | NaN                      | 1.37kg | 1339,69       |\n",
    "| 1 | Apple        | Macbook Air | Ultrabook | 13.3\"       | 1440x900                           | Intel Core i5 1.8GHz       | 8GB  | 128GB Flash Storage | Intel HD Graphics 6000       | macOS            | NaN                      | 1.34kg | 898,94        |\n",
    "| 2 | HP           | 250 G6      | Notebook  | 15.6\"       | Full HD 1920x1080                  | Intel Core i5 7200U 2.5GHz | 8GB  | 256GB SSD           | Intel HD Graphics 620        | No OS            | NaN                      | 1.86kg | 575,00        |\n",
    "| 3 | Apple        | MacBook Pro | Ultrabook | 15.4\"       | IPS Panel Retina Display 2880x1800 | Intel Core i7 2.7GHz       | 16GB | 512GB SSD           | AMD Radeon Pro 455           | macOS            | NaN                      | 1.83kg | 2537,45       |\n",
    "| 4 | Apple        | MacBook Pro | Ultrabook | 13.3\"       | IPS Panel Retina Display 2560x1600 | Intel Core i5 3.1GHz       | 8GB  | 256GB SSD           | Intel Iris Plus Graphics 650 | macOS            | NaN                      | 1.37kg | 1803,60       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GRL7qfnEYXTw"
   },
   "source": [
    "We can start by reading the data into pandas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5tLHEOjZwpg"
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 4: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 4: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-643513e66b96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Did you get an error?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlaptops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"laptops.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlaptops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#This error is about encoding of dataset's read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 4: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# Did you get an error?\n",
    "import pandas as pd\n",
    "laptops = pd.read_csv(\"laptops.csv\")\n",
    "laptops.head()\n",
    "#This error is about encoding of dataset's read "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfCL6eNb-RWf"
   },
   "source": [
    "We get an error! (The actual error is much longer than this, we've truncated it for readability). To understand this error and how to fix it, we need to learn about **encodings**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BW19Iz5edmuf"
   },
   "source": [
    "**A Short History of Encodings**\n",
    "\n",
    "Computers, at their lowest levels, can only understand binary - 0 and 1. Encodings are systems for representing characters in binary. From the early days of computers, the standard for representing text was called ASCII. The ASCII standard specified a set of 128 standard characters - these were letters, numbers and punctuation marks that were used for the English language. For instance, the letter __a__ in ASCII is represented as **01100001** in binary.\n",
    "\n",
    "ASCII was very useful for the basic letters and numbers in the english language, but as the popularity of computers spread worldwide, different computer manufacturers created new encodings to encode different characters, like the greek character $\\alpha$ or the Japanse character も. Because there wasn't one standard for encodings there were problems when you tried to read files saved using one character set with a computer that used a different character set.\n",
    "\n",
    "\n",
    "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1NzDcepAjvJESItrSbykVB3L9SFdLCLaS\">\n",
    "\n",
    "As a result, there ended up being dozens of different encodings being used throughout the early days of the web. Ideally, the person sending you a file would tell you what encoding it is in, however in reality that rarely happened (and still doesn't). Trying to work out what encoding a file was in was relatively difficult, and you often had to guess.\n",
    "\n",
    "These days, we often still have to guess, however in the last 15 years the number of encodings being commonly used has decreased. This means that the vast majority of files are encoded in one of 2-3 formats.\n",
    "\n",
    "\n",
    "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1mPe_Flzn-VfBCZht69_k2rpopYpHqHYY\">\n",
    "\n",
    "\n",
    "The diagram above shows the usage of different encodings on the web. As you can see, **UTF-8** has grown rapidly to be the predominant encoding being used. Because of this trend, the best thing to do if your file has an unknown encoding is to try the most common encodings. The most common encodings are, in order:\n",
    "\n",
    "- UTF-8 (the default for Python)\n",
    "- Latin-1 (also known as ISO-8895-1)\n",
    "- Windows-1251\n",
    "\n",
    "To specify a encoding when reading a CSV file with pandas, simply use the **encoding** argument within the **pandas.read_csv()** function, specifying the encoding as a string:\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"filename.csv\", encoding=\"UTF-8\")\n",
    "```\n",
    "\n",
    "\n",
    "Because **UTF-8** is the default, you don't need to specify it the file you're reading is encoded with **UTF-8** (you'll notice the error message mentions **UTF-8**)\n",
    "\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
    "\n",
    "\n",
    "- Use the **pandas.read_csv()** function to read the **laptops.csv** file into a dataframe **laptops**.\n",
    "  - Specify the encoding using the string **\"Latin-1\"**.\n",
    "  - If that doesn't work, try using the string **\"Windows-1251\"**.\n",
    "- Use the **DataFrame.info()** method to display information about the laptops dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BXD78k3iv7H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1303 entries, 0 to 1302\n",
      "Data columns (total 13 columns):\n",
      "Manufacturer                1303 non-null object\n",
      "Model Name                  1303 non-null object\n",
      "Category                    1303 non-null object\n",
      "Screen Size                 1303 non-null object\n",
      "Screen                      1303 non-null object\n",
      "CPU                         1303 non-null object\n",
      "RAM                         1303 non-null object\n",
      " Storage                    1303 non-null object\n",
      "GPU                         1303 non-null object\n",
      "Operating System            1303 non-null object\n",
      "Operating System Version    1133 non-null object\n",
      "Weight                      1303 non-null object\n",
      "Price (Euros)               1303 non-null object\n",
      "dtypes: object(13)\n",
      "memory usage: 132.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# put your code here \n",
    "import pandas as pd\n",
    "\n",
    "laptops = pd.read_csv(\"laptops.csv\", encoding=\"latin-1\")\n",
    "# laptops.head()\n",
    "laptops = pd.read_csv(\"laptops.csv\", encoding=\"Windows-1251\")\n",
    "\n",
    "laptops.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fkXLBIP2j-gb"
   },
   "source": [
    "## 2 Cleaning Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-SO2OyDYkbBG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Manufacturer',\n",
       " 'Model Name',\n",
       " 'Category',\n",
       " 'Screen Size',\n",
       " 'Screen',\n",
       " 'CPU',\n",
       " 'RAM',\n",
       " ' Storage',\n",
       " 'GPU',\n",
       " 'Operating System',\n",
       " 'Operating System Version',\n",
       " 'Weight',\n",
       " 'Price (Euros)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIw28dVdlolq"
   },
   "source": [
    "As well as being able to use the attribute to view the column labels, we can also assign to the attribute:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "awzvUQ6Yl83I"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'E', 'G', 'F', 'H', 'I', 'J', 'K', 'L', 'M']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops_test = laptops.copy()\n",
    "laptops_test.columns = ['A', 'B', 'C', 'D', 'E',\n",
    "                        'G', 'F', 'H', 'I', 'J',\n",
    "                        'K', 'L', 'M']\n",
    "laptops_test.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9R3uvCNumFcv"
   },
   "source": [
    "We can create a function that uses Python [string methods](https://docs.python.org/3/library/stdtypes.html#string-methods) to clean our column labels, and then use list comprehension to apply that function to each label. Let's look at an example:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSFQZBZ7mbMg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manufacturer',\n",
       " 'model name',\n",
       " 'category',\n",
       " 'screen size',\n",
       " 'screen',\n",
       " 'cpu',\n",
       " 'ram',\n",
       " 'storage',\n",
       " 'gpu',\n",
       " 'operating system',\n",
       " 'operating system version',\n",
       " 'weight',\n",
       " 'price euros']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_col(col):\n",
    "    col = col.strip()\n",
    "    col = col.replace(\"(\",\"\")\n",
    "    col = col.replace(\")\",\"\")\n",
    "    col = col.lower()\n",
    "    return col\n",
    "\n",
    "laptops.columns = [clean_col(c) for c in laptops.columns]\n",
    "laptops.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_4PH9CAemg9V"
   },
   "source": [
    "Let's use this technique to clean the column labels in our dataframe, adding a few extra cleaning 'chores' along the way\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
    "\n",
    "1. Define a function, which accepts a string argument, and:\n",
    "  - Removes any whitespace from the start and end of the string.\n",
    "  - Replaces the substring Operating System with the abbreviation os.\n",
    "  - Replaces all spaces with underscores.\n",
    "  - Removes parentheses from the string.\n",
    "  - Makes the entire string lowercase.\n",
    "  - Returns the modified string.\n",
    "2. Use list comprehension to apply the function to each item in the **DataFrame.column** attribute for the **laptops** dataframe, assigning the result back to the the **DataFrame.columns** attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xhb9rwDtnS_M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manufacturer',\n",
       " 'model_name',\n",
       " 'category',\n",
       " 'screen_size',\n",
       " 'screen',\n",
       " 'cpu',\n",
       " 'ram',\n",
       " 'storage',\n",
       " 'gpu',\n",
       " 'os',\n",
       " 'os_version',\n",
       " 'weight',\n",
       " 'price_euros']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your code here\n",
    "def clean_col(col):\n",
    "    col = col.strip()\n",
    "    col = col.replace(\"Operating System\",\"os\")\n",
    "    col = col.replace(\" \",\"_\")\n",
    "    col = col.replace(\")\",\"\")\n",
    "    col = col.replace(\"(\",\"\")\n",
    "    col = col.lower()\n",
    "    return col\n",
    "\n",
    "\n",
    "laptops.columns = [clean_col(c) for c in laptops.columns]\n",
    "laptops.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5BSVGTuGxTw_"
   },
   "source": [
    "## 3 Converting String Columns to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZKdj0trx7nA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>screen_size</th>\n",
       "      <th>screen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3\"</td>\n",
       "      <td>IPS Panel Retina Display 2560x1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3\"</td>\n",
       "      <td>1440x900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6\"</td>\n",
       "      <td>Full HD 1920x1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>15.4\"</td>\n",
       "      <td>IPS Panel Retina Display 2880x1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>13.3\"</td>\n",
       "      <td>IPS Panel Retina Display 2560x1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category screen_size                              screen\n",
       "0  Ultrabook       13.3\"  IPS Panel Retina Display 2560x1600\n",
       "1  Ultrabook       13.3\"                            1440x900\n",
       "2   Notebook       15.6\"                   Full HD 1920x1080\n",
       "3  Ultrabook       15.4\"  IPS Panel Retina Display 2880x1800\n",
       "4  Ultrabook       13.3\"  IPS Panel Retina Display 2560x1600"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops.iloc[:5,2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTikTuCmyEWX"
   },
   "source": [
    "Of these three columns, we have three different types of text data:\n",
    "\n",
    "- **category** - This is purely text data, there are no numeric values.\n",
    "- **screen_size** - This is numeric data that is being stored as text data because of the \" character.\n",
    "- **screen** - This is a combination of pure text data with numeric data.\n",
    "\n",
    "\n",
    "Thinking about the **screen_size** column specifically, while the values are stored as text data, we can't sort them numerically. For instance, if we wanted to select laptops with screens 15\" or larger we're unable to do so. To be able to answer these sorts of questions we need to convert the string values to numeric values.\n",
    "\n",
    "Whenever we're converting text to numeric data, we can follow this data cleaning workflow:\n",
    "\n",
    "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=12C8ysc6Sd5BcLmpKwIJzlMtVB6_SPQ1D\">\n",
    "\n",
    "\n",
    "Let's walk through the workflow while we convert the **screen_size** column to numeric. The first stage is to explore the data. One of the best ways to do this is to use the **Series.unique()** method to view all of the unique values in the colum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJx7nNhtybJZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['13.3\"', '15.6\"', '15.4\"', '14.0\"', '12.0\"', '11.6\"', '17.3\"',\n",
       "       '10.1\"', '13.5\"', '12.5\"', '13.0\"', '18.4\"', '13.9\"', '12.3\"',\n",
       "       '17.0\"', '15.0\"', '14.1\"', '11.3\"'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(laptops[\"screen_size\"].dtype)\n",
    "laptops[\"screen_size\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ig1QP_UO0ZpE"
   },
   "source": [
    "Our next stage is **to identify patterns and special cases**. We can see that all values in this column follow the same pattern - series of digit and period characters, followed by a quote character. There are no special cases - every value matches the same pattern. We can also observe that we will need to convert the column to a **float dtype**, as the **int dtype** won't be able to store the decimal values.\n",
    "\n",
    "The next stage is **to remove the non-digit characters**. The pandas library contains dozens of vectorized string methods, most of which are available using the **Series.str accessor**. In this case, we can use the **Series.str.replace()** method, which is a vectorized version of the **Python str.replace()** method we used in the previous screen to remove all the quote characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTlYmvhU1RUW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['13.3', '15.6', '15.4', '14.0', '12.0', '11.6', '17.3', '10.1',\n",
       "       '13.5', '12.5', '13.0', '18.4', '13.9', '12.3', '17.0', '15.0',\n",
       "       '14.1', '11.3'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops[\"screen_size\"] = laptops[\"screen_size\"].str.replace('\"','')\n",
    "laptops[\"screen_size\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkv_xvfA1VVa"
   },
   "source": [
    "Now we've **removed the non-digit characters**, we can **convert (or cast)** the column to a numeric dtype. To do this, we use the **Series.astype()** method. We can use either **int** or **float** as the parameter for the method to convert the column to the respective type:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmxyzZPH1nqJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([13.3, 15.6, 15.4, 14. , 12. , 11.6, 17.3, 10.1, 13.5, 12.5, 13. ,\n",
       "       18.4, 13.9, 12.3, 17. , 15. , 14.1, 11.3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops[\"screen_size\"] = laptops[\"screen_size\"].astype(float)\n",
    "print(laptops[\"screen_size\"].dtype)\n",
    "laptops[\"screen_size\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIZH3lgW1r_U"
   },
   "source": [
    "Our column is now the **float64** dtype, and you see that there are no longer quotes around each value denoting them as strings.\n",
    "\n",
    "Our final step is **to rename** the column. This is an optional step, and can be useful if the non-digit values contained information that helps us understand the data. In out case the quote characters actually denoted that the screen size was in inches. We can use the **DataFrame.rename()** method to rename specific axis labels using a dictionary with the keys as the old label name, and the values as the new label name. We'll also need to specify **axis=1** parameter so pandas knows that we want to rename labels in the column axis, and we'll also use **inplace=True** instead of assignment (although assigning back to the DataFrame would give us an identical result):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TK9NFc0_26lZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "manufacturer           object\n",
       "model_name             object\n",
       "category               object\n",
       "screen_size_inches    float64\n",
       "screen                 object\n",
       "cpu                    object\n",
       "ram                    object\n",
       "storage                object\n",
       "gpu                    object\n",
       "os                     object\n",
       "os_version             object\n",
       "weight                 object\n",
       "price_euros            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops.rename({\"screen_size\": \"screen_size_inches\"}, axis=1, inplace=True)\n",
    "laptops.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2vHXiwxs3A3u"
   },
   "source": [
    "We can see that we now have one column converted to a numeric type and renamed appropriately. Our exercise for this lesson will be to follow the process for the **ram** column. We'll do the first two steps together, starting with exploring the data:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_pnLP6d3Kov"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['8GB', '16GB', '4GB', '2GB', '12GB', '6GB', '32GB', '24GB', '64GB'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops[\"ram\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuhaYKXC3NI3"
   },
   "source": [
    "We can easily identify a clear pattern to the data - all values are integers, and include the character **GB** at the end of the string. There aren't any special cases that are exceptions to the pattern.\n",
    "\n",
    "Let's finish the process of converting the **ram** column to a numeric type.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
    "\n",
    "1. Use the **Series.replace()** method to remove the substring **GB** from the ram column.\n",
    "2. Use the **Series.astype()** method to change the **ram** column to an **integer** dtype.\n",
    "3. Because the **GB** characters contained useful information about the units (gigabytes) of the laptop's ram, use the **DataFrame.rename()** method to rename the column from **ram** to **ram_gb.**\n",
    "4. Use the **DataFrame.dtypes** attribute to get a list of the column names and types from the **laptops** dataframe, and assign the result to **dtypes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4bXzR67_5PmC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "manufacturer           object\n",
       "model_name             object\n",
       "category               object\n",
       "screen_size_inches    float64\n",
       "screen                 object\n",
       "cpu                    object\n",
       "ram_gb                float64\n",
       "storage                object\n",
       "gpu                    object\n",
       "os                     object\n",
       "os_version             object\n",
       "weight                 object\n",
       "price_euros            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put your code here\n",
    "laptops['ram'] = laptops[\"ram\"].str.replace(\"GB\",\"\")\n",
    "laptops['ram'] = laptops['ram'].astype(float)\n",
    "laptops.rename({'ram':'ram_gb'}, axis=1, inplace=True)\n",
    "laptops.columns.tolist()\n",
    "dtypes = laptops.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Znyj0OYi7l0a"
   },
   "source": [
    "## 4 Practicing Converting String Columns to Numeric\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXWY9xed7n-K"
   },
   "source": [
    "This workflow is extremely common, so we're going to practice it with the **weight** and **price_euros** columns. Here's a reminder of the workflow\n",
    "\n",
    "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=12C8ysc6Sd5BcLmpKwIJzlMtVB6_SPQ1D\">\n",
    "\n",
    "Let's start with the **weight** column:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1fIui_G71tg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.37kg', '1.34kg', '1.86kg', '1.83kg', '2.1kg', '2.04kg', '1.3kg',\n",
       "       '1.6kg', '2.2kg', '0.92kg', '1.22kg', '0.98kg', '2.5kg', '1.62kg',\n",
       "       '1.91kg', '2.3kg', '1.35kg', '1.88kg', '1.89kg', '1.65kg',\n",
       "       '2.71kg', '1.2kg', '1.44kg', '2.8kg', '2kg', '2.65kg', '2.77kg',\n",
       "       '3.2kg', '0.69kg', '1.49kg', '2.4kg', '2.13kg', '2.43kg', '1.7kg',\n",
       "       '1.4kg', '1.8kg', '1.9kg', '3kg', '1.252kg', '2.7kg', '2.02kg',\n",
       "       '1.63kg', '1.96kg', '1.21kg', '2.45kg', '1.25kg', '1.5kg',\n",
       "       '2.62kg', '1.38kg', '1.58kg', '1.85kg', '1.23kg', '1.26kg',\n",
       "       '2.16kg', '2.36kg', '2.05kg', '1.32kg', '1.75kg', '0.97kg',\n",
       "       '2.9kg', '2.56kg', '1.48kg', '1.74kg', '1.1kg', '1.56kg', '2.03kg',\n",
       "       '1.05kg', '4.4kg', '1.90kg', '1.29kg', '2.0kg', '1.95kg', '2.06kg',\n",
       "       '1.12kg', '1.42kg', '3.49kg', '3.35kg', '2.23kg', '4.42kg',\n",
       "       '2.69kg', '2.37kg', '4.7kg', '3.6kg', '2.08kg', '4.3kg', '1.68kg',\n",
       "       '1.41kg', '4.14kg', '2.18kg', '2.24kg', '2.67kg', '2.14kg',\n",
       "       '1.36kg', '2.25kg', '2.15kg', '2.19kg', '2.54kg', '3.42kg',\n",
       "       '1.28kg', '2.33kg', '1.45kg', '2.79kg', '1.84kg', '2.6kg',\n",
       "       '2.26kg', '3.25kg', '1.59kg', '1.13kg', '1.78kg', '1.10kg',\n",
       "       '1.15kg', '1.27kg', '1.43kg', '2.31kg', '1.16kg', '1.64kg',\n",
       "       '2.17kg', '1.47kg', '3.78kg', '1.79kg', '0.91kg', '1.99kg',\n",
       "       '4.33kg', '1.93kg', '1.87kg', '2.63kg', '3.4kg', '3.14kg',\n",
       "       '1.94kg', '1.24kg', '4.6kg', '4.5kg', '2.73kg', '1.39kg', '2.29kg',\n",
       "       '2.59kg', '2.94kg', '1.14kg', '3.8kg', '3.31kg', '1.09kg',\n",
       "       '3.21kg', '1.19kg', '1.98kg', '1.17kg', '4.36kg', '1.71kg',\n",
       "       '2.32kg', '4.2kg', '1.55kg', '0.81kg', '1.18kg', '2.72kg',\n",
       "       '1.31kg', '0.920kg', '3.74kg', '1.76kg', '1.54kg', '2.83kg',\n",
       "       '2.07kg', '2.38kg', '3.58kg', '1.08kg', '2.20kg', '2.75kg',\n",
       "       '1.70kg', '2.99kg', '1.11kg', '2.09kg', '4kgs', '3.0kg', '0.99kg',\n",
       "       '3.52kg', '2.591kg', '2.21kg', '3.3kg', '2.191kg', '2.34kg',\n",
       "       '4.0kg'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops.weight.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDRDjxL-8KN2"
   },
   "source": [
    "While it appears that the **weight** column may just need the **kg** characters removed from the end of each string, there are a lot of unique values for the weight column, so it's hard to visually confirm if there are any exceptions to the pattern.\n",
    "\n",
    "If we can't see any exceptions, it's OK to move forward onto the next step, as if we miss any, the error we get will tell us the value so we can fix it. Let's see if we missed anything– we're going to use method chaining to attempt both removing the **kg** characters and casting to the **float**, but we'll use a new formatting trick for method chaining. By putting our code inside parentheses, we can method chain over multiple lines, which makes our code easier to read.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0l6sag_I8yq-"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '4s'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-747c359d053d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m laptops[\"weight\"] = (laptops[\"weight\"]\n\u001b[1;32m      3\u001b[0m                      \u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                      \u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   4999\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5000\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 5001\u001b[0;31m                                          **kwargs)\n\u001b[0m\u001b[1;32m   5002\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3713\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3714\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3580\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3581\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3582\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 575\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, klass, mgr, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                 \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '4s'"
     ]
    }
   ],
   "source": [
    "\n",
    "laptops[\"weight\"] = (laptops[\"weight\"]\n",
    "                     .str.replace(\"kg\",\"\")\n",
    "                     .astype(float)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3998QR0w87G3"
   },
   "source": [
    "We've hit an error– **a ValueError** to be precise (we've truncated the error output to make it easier to read, but you will always find the value in question at the very bottom of the error). The error tells us which value it couldn't convert to a float **'4s'**. Keep in mind that this is the value after the **kg** has been replaced because of our method chaining, so the value substring **'4s'** may not actually exist in the raw data. We can use the pandas **Series.str.contains()** method, which returns a boolean series based on whether a substring is found to look at the raw value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8giqV1E391zU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061    4kgs\n",
       "Name: weight, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops.loc[laptops[\"weight\"].str.contains('s'), \"weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hp7bhTLO9_iV"
   },
   "source": [
    "We have identified the special case - we need to remove **kgs** before **kg**, or alternatively we could remove **kg** and then **s**. There's the possibility that there might be more than one exception, because the error will stop the rest of the values from being processed. We'll leave that final step up to you in the exercise at the end of this screen.\n",
    "\n",
    "Next, let's look at the **price_euros** column. This column has almost 800 unique values, so we're going to look at the first and last 5 as a sample:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvHOWfXcAepZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1339,69' '898,94' '575,00' '2537,45' '1803,60']\n",
      "['549,99' '805,99' '720,32' '638,00' '764,00']\n"
     ]
    }
   ],
   "source": [
    "print(laptops[\"price_euros\"].unique()[:5])\n",
    "print(laptops[\"price_euros\"].unique()[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BLhagpgLAyRd"
   },
   "source": [
    "You may not have seen this style of writing decimals with a comma instead of a period, which is used in parts of South America, Africa and Europe (you might like to read more about [decimal commas](https://en.wikipedia.org/wiki/Decimal_separator#Hindu%E2%80%93Arabic_numeral_system)). In this case, simply removing the comma will give us incorrect values– we'll need to replace with with a period.\n",
    "\n",
    "Now that we've done some exploration together, let's finish off the cleaning of both of these columns.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
    "\n",
    "\n",
    "1. Clean the **weight** column by:\n",
    "  - Removing all non-digit characters.\n",
    "  - Casting the column to the appropriate numeric type\n",
    "  - Renaming the column to **weight_kg**.\n",
    "2. Clean the **price_euros** column by:\n",
    "  - Replacing the decimal commas with decimal points.\n",
    "  - Casting the column to the appropriate numeric type.\n",
    "3. Use the **Series.describe()** method to generate some descriptive statistics for each column:\n",
    "  - Assign the results for the **weight_kg** column to **weight_describe**.\n",
    "  - Assign the results for the **price_euros** column to **price_describe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pXbmA7PBXOI"
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "# 1 exercise\n",
    "laptops['weight'] = laptops['weight'].str.replace(\"kg\",\"\")\n",
    "laptops['weight'] = laptops['weight'].str.replace(\"s\",\"\")\n",
    "laptops.loc[laptops[\"weight\"].str.contains('s'), \"weight\"]\n",
    "laptops['weight'] = laptops['weight'].astype(float)\n",
    "laptops['weight'].unique()\n",
    "laptops.rename({'weight':'weight_kg'}, axis=1, inplace= True)\n",
    "laptops.columns.tolist()\n",
    "\n",
    "\n",
    "# 2 exercise\n",
    "laptops['price_euros'] = laptops['price_euros'].str.replace(\",\",\".\")\n",
    "laptops['price_euros'] = laptops['price_euros'].astype(float)\n",
    "\n",
    "#3 exercise\n",
    "weight_describe = laptops['weight_kg'].describe()\n",
    "price_describe = laptops['price_euros'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ccTH6UqvFJht"
   },
   "source": [
    "\n",
    "## 5 Extracting Values from the Start of Strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1dytGjKB1J5"
   },
   "source": [
    "\n",
    "From the previous screen, we can see that the average (mean) laptop weights around 2kg and costs just over 1,100 euros.\n",
    "\n",
    "Sometimes, it can be useful to extract non-numeric values from within strings. Let's look at the first 10 values from the **gpu** (graphics processing unit) column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 678,
     "status": "ok",
     "timestamp": 1537046068644,
     "user": {
      "displayName": "Ivanovitch Silva",
      "photoUrl": "//lh4.googleusercontent.com/-baHwkIBEacY/AAAAAAAAAAI/AAAAAAAAFo0/aWRaXNQgy7Q/s50-c-k-no/photo.jpg",
      "userId": "116628038672433119071"
     },
     "user_tz": 180
    },
    "id": "QSH5Nz2GFZn9",
    "outputId": "eb8489a3-c401-45fa-9930-851fa6719b32"
   },
   "outputs": [],
   "source": [
    "laptops[\"gpu\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtunpBljFbqf"
   },
   "source": [
    "The information in this column seems to be a manufacturer followed by a model name/number. The manufacturers in the subset are just the first word of each value: Intel, AMD, Nvidia. Extracting the manufacturer by itself would be useful, as we can analyze who are the most common GPU manufacturers.\n",
    "\n",
    "Because each manufacturer is followed by a whitespace character, we can use the **Series.str.split()** method to extract this data. Let's look how we use this method to extract the data.\n",
    "\n",
    "First, we'll use **Series.head()** to look at just the first five items:\n",
    "\n",
    "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1cjQOzRy2pFfEntvcoQY8zzZwi-OcfWH2\">\n",
    "\n",
    "Net's we'll start by using **Series.str.split()** with the default parameters:\n",
    "\n",
    "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1j_p4vBq4DH6MqmqpLrDCc6aWvxEJztkg\">\n",
    "\n",
    "The method has split each string on the whitespace, and the result is individual Python lists stored within a series. The **Series.str.split()** method accepts an argument **n**, which controls the maximum number of splits allowed. By using **n=1**, the method will make a single split on the first whitespace:\n",
    "\n",
    "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1SG2mTLap_Ym7mi1epG9U0upKN7hYL_da\">\n",
    "\n",
    "Manipulating Python lists inside a Series can be cumbersome. Instead, we can use the **expand=True** argument which will expand our series of lists into a dataframe:\n",
    "\n",
    "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1RKx_YuufvLXt-ei1pyu54SIQjfF7bpzY\">\n",
    "\n",
    "Lastly, we can use **DataFrame.iloc[]** to select only the first column:\n",
    "\n",
    "\n",
    "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1HjB3Ry_pnvtdj_K11bWaturCwBbyFOsz\">\n",
    "\n",
    "\n",
    "Let's use this technique to extract the manufacturer from the **cpu** column as well. Here are the first 10 rows of the **cpu** column, you'll see they follow a similar format to the **gpu** column:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMSTPU5BGJ7q"
   },
   "outputs": [],
   "source": [
    "laptops.cpu.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j8uCY4H8Ixg4"
   },
   "source": [
    "**Exercise**\n",
    "\n",
    "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
    "\n",
    "\n",
    "1. In the example code, we have extracted the **manufacturer name** from the **gpu** column, and assigned it to a new column **gpu_manufacturer.**\n",
    "\n",
    "  - Extract the **manufacturer name** from the **cpu** column, and assign it to a new column **cpu_manufacturer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocZ7IlSVJR6S"
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aVwYEROIJfsy"
   },
   "source": [
    "## 6 Extracting Values from the End of Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CXE-6AtJ4pY"
   },
   "source": [
    "\n",
    "Next, let's look at the **screen** column:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1537047535803,
     "user": {
      "displayName": "Ivanovitch Silva",
      "photoUrl": "//lh4.googleusercontent.com/-baHwkIBEacY/AAAAAAAAAAI/AAAAAAAAFo0/aWRaXNQgy7Q/s50-c-k-no/photo.jpg",
      "userId": "116628038672433119071"
     },
     "user_tz": 180
    },
    "id": "Y2WGu9c9K77i",
    "outputId": "198df41a-403c-4d50-b890-01bd38b0b9e5"
   },
   "outputs": [],
   "source": [
    "print(laptops[\"screen\"].unique().shape)\n",
    "print(laptops[\"screen\"].unique()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RU2KkbGiLB3h"
   },
   "source": [
    "There are 40 unique values, so we'll just look at the first 10. Some of the values have just the resolution (eg **'1440x900'**), while others have information on the type of screen and then end with the resolution. While the resolution is mostly numeric, we're going to treat the resolution as as a substring that we want to extract. Let's start by seeing what we get when we use **Series.str.split()**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qj_YjghaLk8x",
    "outputId": "e3e57973-6b32-48b9-9844-f700ccebc2f0"
   },
   "outputs": [],
   "source": [
    "laptops.loc[:9, \"screen\"].str.split(expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBINM8vcLqsg"
   },
   "source": [
    "Five of the rows have the resolution in column 4, two have it in column 2 and the rest have it in column 1. Because the value we want to extract is from the end of the string and not the beginning of the string, the **n=1** parameter is not going to help us. Luckily the **Series.str.rsplit()** method allows us to split from the end of the string instead of the front.\n",
    "\n",
    "Let's look at a quick example to see the different between **Series.str.rsplit()** and **Series.str.split()**. We'll use a sample series called sentences:\n",
    "\n",
    "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1QJUgCe5cj38Xe-8Xlb8B63Vgjd1CQHOJ\">\n",
    "\n",
    "Let's use **Series.str.split()** with n=1:\n",
    "\n",
    "\n",
    "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1eipfc5ZVLJyZ5cN_Re7RQc3g5NosRz_A\">\n",
    "\n",
    "\n",
    "We have split the first word from the start of the string, effectively extracting a series of names. Next, let's use **Series.str.rsplit()** on the original sentences series:\n",
    "\n",
    "\n",
    "<img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1_ON37DLE1xegsXHFUQ9NhmBODpOO7ebr\">\n",
    "\n",
    "\n",
    "We have split the first word from the end of the string, effectively creating a series of colors.\n",
    "\n",
    "Now that we understand how **Series.str.rsplit()** works, let's look at how we can use it to extract the resolutions from our screen column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SxoVvfh8MPTw"
   },
   "outputs": [],
   "source": [
    "laptops.loc[:9, \"screen\"].str.rsplit(n=1, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9siigfkpN0tx"
   },
   "source": [
    "This is much closer to what we're looking for - almost all of the resolution substrings are in column 1, and those that don't have the resolution in column 0 and have a null value in column 1. We can use **Series.isnull()** to assign just to the rows with the **null values**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxThRwyjSJ2J"
   },
   "outputs": [],
   "source": [
    "screen_res = laptops[\"screen\"].str.rsplit(n=1, expand=True)\n",
    "\n",
    "# giving the columns string labels makes them easier to work with\n",
    "screen_res.columns = [\"A\", \"B\"]\n",
    "\n",
    "# for rows where the value of column \"B\" is null, fill in the\n",
    "# value found in column \"A\" for that row\n",
    "screen_res.loc[screen_res[\"B\"].isnull(), \"B\"] = screen_res[\"A\"]\n",
    "\n",
    "screen_res.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SjBK9tjHSewa"
   },
   "source": [
    "We've now extracted the resolution data, and we can then assign this to a new column:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eo6KXik3Snnu"
   },
   "outputs": [],
   "source": [
    "laptops[\"screen_resolution\"] = screen_res[\"B\"]\n",
    "print(laptops[\"screen_resolution\"].unique().shape)\n",
    "laptops[\"screen_resolution\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2djhe7hLSqiK"
   },
   "source": [
    "Our new **screen_resolution** column has just 15 unique values, down from the original 40. Let's use a similar technique to extract the **CPU speed** from the **cpu** column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U006ZGIMTNaL"
   },
   "outputs": [],
   "source": [
    "laptops[\"cpu\"].unique()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4CZO-JrTQoZ"
   },
   "source": [
    "From this data, we want to extract the processor **speed** as a number, eg from the string **'Intel Core i5 2.3GHz'** we want to extract a **float 2.3**.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
    "\n",
    "- From the **cpu** column, perform the following steps to extract and convert the **processor speed**, assigning the results to a new column **cpu_speed_ghz**:\n",
    "  - Use **Series.str.replace()** to remove the substring **\"GHz\"** each string.\n",
    "  - Use **Series.str.rsplit()** and **DataFrame.iloc[]** to select the numeric characters from the end of the string.\n",
    "  - Use **Series.astype()** to cast the values to the **float dtype**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_VXuSURjU59D"
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItZt1vX4WAcb"
   },
   "source": [
    "## 7 Correcting Bad Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NV8GUvdmB7l5"
   },
   "source": [
    "\n",
    "If your data has been scraped from a webpage, or if there was manual data entry involved at some point, you may end up with inconsistent values. Let's look at an example from our **os** column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 663,
     "status": "ok",
     "timestamp": 1537050491191,
     "user": {
      "displayName": "Ivanovitch Silva",
      "photoUrl": "//lh4.googleusercontent.com/-baHwkIBEacY/AAAAAAAAAAI/AAAAAAAAFo0/aWRaXNQgy7Q/s50-c-k-no/photo.jpg",
      "userId": "116628038672433119071"
     },
     "user_tz": 180
    },
    "id": "DR-c3bmdWK5N",
    "outputId": "48890827-861a-468c-bcb9-3ed2debf5a5f"
   },
   "outputs": [],
   "source": [
    "laptops.os.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INx2SWM1WTYf"
   },
   "source": [
    "We can see that there are two variations on how the Apple operating system **macOS** exists in our dataset: **Mac OS** and **macOS**. One way we could fix this is by using a boolean comparison and assignment, but instead we'll learn a new way: the [Series.map()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html) method. The **Series.map()** method is ideal when we want to change multiple values in a column. Even though that's not the case here, we'll use it as an opportunity to learn how the method works.\n",
    "\n",
    "The most common way to use **Series.map()** is with a dictionary. The keys of our dictionary are the original values in our series, and the corresponding values are what they're updated to. Let's look at a simple example using a series of misspelled fruit:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9jtHbVyWwj8"
   },
   "outputs": [],
   "source": [
    "s = pd.Series([\"pair\",\"oranje\",\"bananna\",\"oranje\",\"oranje\",\"oranje\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXOmHve5XixL"
   },
   "source": [
    "We'll create a **dictionary** called corrections and pass that dictionary as an argument to **Series.map()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1537050875929,
     "user": {
      "displayName": "Ivanovitch Silva",
      "photoUrl": "//lh4.googleusercontent.com/-baHwkIBEacY/AAAAAAAAAAI/AAAAAAAAFo0/aWRaXNQgy7Q/s50-c-k-no/photo.jpg",
      "userId": "116628038672433119071"
     },
     "user_tz": 180
    },
    "id": "3p8W2ob5XsJp",
    "outputId": "11506fda-02c0-41e2-c542-3783109ef2f7"
   },
   "outputs": [],
   "source": [
    "corrections = {\n",
    "    \"pair\": \"pear\",\n",
    "    \"oranje\": \"orange\",\n",
    "    \"bananna\": \"banana\"\n",
    "}\n",
    "\n",
    "s = s.map(corrections)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-r6s4IaHYCu6"
   },
   "source": [
    "We can see that each of our corrections were made across our series. One important thing to remember with **Series.map()** is that if a value from your series doesn't exist as a key in your dictionary, it will convert that value to **NaN**. Let's see what happens when we run map one more time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 713,
     "status": "ok",
     "timestamp": 1537050965111,
     "user": {
      "displayName": "Ivanovitch Silva",
      "photoUrl": "//lh4.googleusercontent.com/-baHwkIBEacY/AAAAAAAAAAI/AAAAAAAAFo0/aWRaXNQgy7Q/s50-c-k-no/photo.jpg",
      "userId": "116628038672433119071"
     },
     "user_tz": 180
    },
    "id": "ihIoQkpQXxU1",
    "outputId": "836909e9-ce26-4ac8-dbc4-8f71bbc30e8e"
   },
   "outputs": [],
   "source": [
    "s.map(corrections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DYpzSKqzX-Xy"
   },
   "source": [
    "Because none of the corrected values in our series existed as keys in our dictionary, all values become **NaN**! It's very common to come across this, **especially when working in Jupyter notebook where you can easily re-run cells**.\n",
    "\n",
    "Let's use **Series.map()** to clean the values in the **os** column.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
    "\n",
    "\n",
    "1. We have created a dictionary for you to use with mapping. Note that we have included both the correct and incorrect spelling of macOS as keys, otherwise we'll end up with null values.\n",
    "  - Use the **Series.map()** method with the **mapping_dict** dictionary to correct the values in the **os** column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3RZW2ffYRcT"
   },
   "outputs": [],
   "source": [
    "mapping_dict = {\n",
    "    'Android': 'Android',\n",
    "    'Chrome OS': 'Chrome OS',\n",
    "    'Linux': 'Linux',\n",
    "    'Mac OS': 'macOS',\n",
    "    'No OS': 'No OS',\n",
    "    'Windows': 'Windows',\n",
    "    'macOS': 'macOS'\n",
    "}\n",
    "\n",
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSNsLsidYroC"
   },
   "source": [
    "## 8 Dropping Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s3f009kdB_z2"
   },
   "source": [
    "\n",
    "In previous missions, we've talked briefly about missing values, and how both NumPy and pandas represent these as null values. In pandas null values will be indicated by either **NaN** or **None**. Generally the first thing that we want to do is identify which values are missing.\n",
    "\n",
    "There are two approaches we can use: the **DataFrame.info()** method and the **DataFrame.isnull()** method. The **DataFrame.info()** method will print information about the dataframe, including the number of **non-null** values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilSSHD8Db_1l"
   },
   "outputs": [],
   "source": [
    "laptops.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sP0fI9xYcBGm"
   },
   "source": [
    "There are two downsides to this approach \n",
    "  - firstly the information is printed, so we can't easily work with it, \n",
    "  - and secondly looking at the number of non-null values can be harder to understand than looking at the number of null values. \n",
    "  \n",
    "In contrast, **DataFrame.isnull()** returns a boolean dataframe with **True** and **False** indications for every value in the dataframe, and then we can use **DataFrame.sum()** to give us accounts– using a **.sum()** method on a boolean array will give us a count of the **True** values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h6UW671lcU-B"
   },
   "outputs": [],
   "source": [
    "laptops.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iyiiVnzQcZl2"
   },
   "source": [
    "It's a lot clearer that we have only one column with null values– **os_version**, which has 170 missing values of the ~1300 total, about 13%.\n",
    "\n",
    "We have a few options for how we can handle missing values:\n",
    "\n",
    "- Remove any rows that have missing values.\n",
    "- Remove any columns that have missing values.\n",
    "- Fill the missing values with some other value.\n",
    "- Leave the missing values as is.\n",
    "\n",
    "The first two options, removing columns and/or rows with missing values is often used when preparing data for machine learning, as machine learning algorithms are unable to be trained on data that includes null values. The methods that we use to remove rows and columns with null values is the **DataFrame.dropna()** method. As a result, removing columns and rows is commonly known as **dropping**.\n",
    "\n",
    "The **DataFrame.dropna()** method accepts an **axis** parameter, which indicates whether we want to drop along the column or index axis. Let's look at an example of this using an example dataframe:\n",
    "\n",
    "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1ekeSgwQGmBjbHLQwcNyWp7QyGlH9JHgE\">\n",
    "\n",
    "The default value for the axis parameter is 0, so **df.dropna()** returns an identical result to **df.dropna(axis=0)**:\n",
    "\n",
    "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1otmPswYfIZ0RHuHVcvYAy4hN5-Z7lqN4\">\n",
    "\n",
    "\n",
    "The rows with labels x and z contain null values, so those values are dropped. Let's look at what happens when we use **axis=1** to specify the column axis:\n",
    "\n",
    "\n",
    "<img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1ygwufYovi1TvKzhzyP5X72l96wOHyDdU\">\n",
    "\n",
    "Only the column with label C contains null values, so in this case just one column is removed.\n",
    "\n",
    "Based off our earlier exercises to identify which columns contain null values, and how many, we know that these two techniques will remove 170 rows and 1 column, respectively. Let's practice using **DataFrame.dropna()** to remove rows and columns:\n",
    "\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
    "\n",
    "\n",
    "\n",
    "- Use **DataFrame.dropna()** to remove any rows from the **laptops** dataframe that have null values, assigning the result to **laptops_no_null_rows**.\n",
    "- Use **DataFrame.dropna()** to remove any columns from the **laptops** dataframe that have null values, assigning the result to **laptops_no_null_cols**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmWNysiJfxvB"
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IP_iO8PTf2Fl"
   },
   "source": [
    "## 9 Filling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SB3rzpa7CCXZ"
   },
   "source": [
    "\n",
    "\n",
    "In the previous screen, we learned there are various ways we can choose to deal with missing values:\n",
    "\n",
    "- Remove any rows that have missing values.\n",
    "- Remove any columns that have missing values.\n",
    "- Fill the missing values with some other value.\n",
    "- Leave the missing values as is.\n",
    "\n",
    "While choosing to drop either the **rows** or **columns** is the easiest approach to dealing with missing values, it may not always be the best approach. If, for example, one particular manufacturer's laptops have a greater percentage of missing values for the **os_version** column, we might have removed a disproportionate amount of that manufacturer's laptops, which would affect our analysis.\n",
    "\n",
    "Because of this, it's worthwhile exploring the missing values before you make your decision. One method is to explore all of the values in the column. We can use **Series.value_counts()** for this, but we'll use a new parameter we haven't previously used, **dropna=False**. By default, **Series.value_counts()** won't include null values in its output. This parameter allows us to explicitly indicate we want to see the null values:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGI5Z0LDivqL"
   },
   "outputs": [],
   "source": [
    "laptops[\"os_version\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ob4D-vUeizb0"
   },
   "source": [
    "We can see that the majority of values in the column are **10**, with the missing values the next most commons, and then about 5% of values being one of three others.\n",
    "\n",
    "We can also explore values of the other columns in the rows with null values. In this case, the **os_version** column is closely related to the os column, so we'll look at those values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "twTLHt5mi8-0"
   },
   "outputs": [],
   "source": [
    "os_with_null_v = laptops.loc[laptops[\"os_version\"].isnull(),\"os\"]\n",
    "os_with_null_v.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OtCcHrtOjE__"
   },
   "source": [
    "Immediately we can observe a few things:\n",
    "\n",
    "- Most of the missing values are actually when the laptop doesn't include any OS. This is an important distinction, because it's not so much that we don't know what the value is, as that there can't be a value.\n",
    "- 13 of the laptops that come with macOS do not specify the version. Leaning on our knowledge of MacOS, we might know that the full name of macOS used to be Mac OS X, and so we might to fill these values to be more consistent.\n",
    "\n",
    "In both of these cases, we can fill the missing values to make our data more correct. For the rest of the values, it's probably best to leave them as missing so we don't remove important values.\n",
    "\n",
    "First, let's explore those mac columns a bit more to make sure our intuition was correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9yI_Sp4gjVsR"
   },
   "outputs": [],
   "source": [
    "mac_os_versions = laptops.loc[laptops[\"os\"] == \"macOS\", \"os_version\"]\n",
    "mac_os_versions.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dj_lgRT3kigh"
   },
   "outputs": [],
   "source": [
    "laptops.loc[laptops[\"os\"] == \"macOS\", \"os_version\"] = \"X\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiV9a8NImVEd"
   },
   "source": [
    "For our other case, let's insert a **No OS** value into the **os_version** column for any laptop with a **No OS** value in the **os** column.\n",
    "\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
    "\n",
    "\n",
    "- Use a boolean array to identify rows that have the value **No OS** for the **os** column, and then use assignment to assign the value **Version Unknown** to the **os_version** column for those rows.\n",
    "- Use the syntax below to create **value_counts_after** variable:\n",
    "\n",
    "```python\n",
    "value_counts_after = laptops.loc[laptops[\"os_version\"].isnull(), \"os\"].value_counts()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPo_3Z5jmkzg"
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buSllVWVn3l3"
   },
   "source": [
    "## 10 Challenge: Extracting Storage Information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3vVZn7fCH4Z"
   },
   "source": [
    "\n",
    "Now it's time for a challenge to bring together a lot of the concepts we've learned so far! In this challenge we're going to clean the storage column, which contains information about the disks within the laptops. Let's look at a sample of the data in that column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1537056508292,
     "user": {
      "displayName": "Ivanovitch Silva",
      "photoUrl": "//lh4.googleusercontent.com/-baHwkIBEacY/AAAAAAAAAAI/AAAAAAAAFo0/aWRaXNQgy7Q/s50-c-k-no/photo.jpg",
      "userId": "116628038672433119071"
     },
     "user_tz": 180
    },
    "id": "mTz5Pve-tMnL",
    "outputId": "bf277d41-ad4e-4c6e-c5b7-41c9787b5a3b"
   },
   "outputs": [],
   "source": [
    "laptops.loc[76:81, \"storage\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMsTRZh_tQaY"
   },
   "source": [
    "From this sample, we can observe:\n",
    "\n",
    "- Some laptops have two disks and some just have one.\n",
    "- Each disk has a capacity (eg 128GB) and a type (eg SSD).\n",
    "- Capacities are expressed in either gigabytes (GB) or terabytes (TB).\n",
    "\n",
    "Our aim is to extract this data into several new columns. Our final data will looks like this:\n",
    "\n",
    "\n",
    "| _  | storage_1_capacity_gb | storage_1_type | storage_2_capacity_gb | storage_2_type |\n",
    "|----|-----------------------|----------------|-----------------------|----------------|\n",
    "| 76 | 2000.0                | HDD            | NaN                   | None           |\n",
    "| 77 | 128.0                 | SSD            | 1000.0                | HDD            |\n",
    "| 78 | 1000.0                | HDD            | NaN                   | None           |\n",
    "| 79 | 128.0                 | SSD            | 1000.0                | HDD            |\n",
    "| 80 | 256.0                 | SSD            | NaN                   | None           |\n",
    "| 81 | 512.0                 | SSD            | NaN                   |  None              |\n",
    "\n",
    "\n",
    "- The **storage_1_capacity_gb** and **storage_2_capacity_gb** columns are both **float** type, and both store the capacity with uniform units - gigabytes, where 1TB is 1000GB.\n",
    "- If there is only one disk in the laptop, both **storage_2_capacity_gb** and **storage_2_type** are null.\n",
    "\n",
    "\n",
    "Your task is to create the four new columns as seen above, and remove the existing storage column. To remove a column, you can use the **DataFrame.drop()** method:\n",
    "\n",
    "```python\n",
    "laptops = laptops.drop('storage', axis=1)\n",
    "```\n",
    "\n",
    "If you create any temporary columns along the way in order to complete these challenge, **DataFrame.drop()** accepts a list of labels so you can remove them all in one line.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
    "\n",
    "1. Clean the **storage** column, creating four new columns:\n",
    "  - **storage_1_capacity_gb**, with **float** dtype.\n",
    "  - **storage_1_type**.\n",
    "  - **storage_2_capacity_gb**, with **float** dtype. If there is only one drive, this column should be null.\n",
    "  - **storage_2_type**. If there is only one drive, this column should be null.\n",
    "  - If needed, don't forget to strip the columns of any extra whitespace.\n",
    "2. Drop the **original storage** column and any temporary columns you made while completing the exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5XzMJ0m2KxU"
   },
   "outputs": [],
   "source": [
    "# tip\n",
    "\n",
    "# replace 'TB' with 000 and rm 'GB'\n",
    "laptops[\"storage\"] = laptops[\"storage\"].str.replace('GB','').str.replace('TB','000')\n",
    "\n",
    "# split out into two columns for storage\n",
    "laptops[[\"storage_1\", \"storage_2\"]] = laptops[\"storage\"].str.split(\"+\", expand=True)\n",
    "\n",
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JDbF43x4lGt"
   },
   "source": [
    "## 11 Reordering Columns and Exporting Cleaned Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEGwXiBHCLrD"
   },
   "source": [
    "\n",
    "We have finished cleaning our data. Our last step is to reorder the columns, and then save out our cleaned data to a CSV file, so that we can re-read it again as a clean version.\n",
    "\n",
    "To reorder columns, we start by using the **DataFrame.columns** attribute to produce a list of the current columns:\n",
    "\n",
    "```python\n",
    "print(laptops.columns)\n",
    "\n",
    "['manufacturer', 'model_name', 'category', 'screen_size_inches',\n",
    " 'screen', 'cpu', 'ram_gb', 'gpu', 'os', 'os_version',\n",
    " 'weight_kg', 'price_euros', 'cpu_manufacturer',\n",
    " 'screen_resolution', 'cpu_speed', 'storage_1_capacity_gb',\n",
    " 'storage_1_type', 'storage_2_capacity_gb', 'storage_2_type']\n",
    "```\n",
    "\n",
    "All of our new columns have been added to the end of the axis– our aim is to group similar columns together. We can manually rearrange this list, and then assign the rearranged list back to laptops.column.\n",
    "\n",
    "To save out our CSV file, we use the **DataFrame.to_csv()** method. The syntax you'll use most of the time when saving out a CSV is:\n",
    "\n",
    "```python\n",
    "df.to_csv('filename.csv', index=False)\n",
    "```\n",
    "\n",
    "By default, pandas will save the index labels as a column in the CSV file. Our dataset has integer labels which don't contain any data, so we don't need to save the index out.\n",
    "\n",
    "Let's re-order the columns, save out the cleaned CSV, and then re-read it into a new dataframe to compare the dtypes before and after.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
    "\n",
    "- Using the **cols** list we have created for laptops, reorder the columns in the laptops dataframe.\n",
    "- Use the **DataFrame.to_csv()** method to save the laptops dataframe to a CSV file **laptops_cleaned.csv** without index labels.\n",
    "- Read **laptops_cleaned.csv** into a new dataframe, **laptops_cleaned**.\n",
    "- Use the **DataFrame.dtypes** attribute to assign the dtypes from **laptops_cleaned** to **laptops_cleaned_dtypes**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3M40-au57hgP"
   },
   "outputs": [],
   "source": [
    "laptops_dtypes = laptops.dtypes\n",
    "cols = ['manufacturer', 'model_name', 'category', 'screen_size_inches',\n",
    "        'screen', 'cpu', 'cpu_manufacturer',  'cpu_speed', 'ram_gb',\n",
    "        'storage_1_type', 'storage_1_capacity_gb', 'storage_2_type',\n",
    "        'storage_2_capacity_gb', 'gpu', 'gpu_manufacturer', 'os',\n",
    "        'os_version', 'weight_kg', 'price_euros']\n",
    "\n",
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1mzlgB49EZs"
   },
   "source": [
    "## 12 Next steps\n",
    "\n",
    "When we re-read in our dataframe, we got identical dtypes! It's often a good idea to save out a CSV when you finish cleaning to save you time should you wish to do analysis later.\n",
    "\n",
    "Our dataset is now primed for analysis. Here are some questions you might like to answer in your own time by analyzing the cleaned data:\n",
    "\n",
    "- Are laptops made by Apple more expensive than those by other manufacturers?\n",
    "- What is the best value laptop with a screen size of 15\" or more?\n",
    "- Which laptop has the most storage space? "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson_05 Data Cleaning Basics.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
